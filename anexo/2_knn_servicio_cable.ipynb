{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67RBrvkUviuj"
   },
   "source": [
    "<a href=\"https://www.inove.com.ar\"><img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/PA%20Banner.png\" width=\"1000\" align=\"center\"></a>\n",
    "\n",
    "\n",
    "# Ejercicio de clasificación con vecinos cercanos (KNN)\n",
    "\n",
    "Ejemplo de clasificación utilizando vecinos cercanos para la clasificación de drogadas que debería tomar un pasiente según su historial clínico<br>\n",
    "\n",
    "v2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnskMOx9-eh0"
   },
   "source": [
    "### Objetivos: \n",
    "*   Preprocesar los datos (descarga, lectura, limplieza y filtrado).\n",
    "*   Conocer como funciona el algoritmo clasificación con KNN (KNeighborsClassifier).\n",
    "*   Evaluar el resultado el algoritmo clasificación con KNN (KNeighborsClassifier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScMGmfO0_wA1"
   },
   "source": [
    "**KNN:** Clasificador que implementa el voto de k-vecinos más cercanos.\n",
    "\n",
    "Fuente: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2sSeyEovSw-"
   },
   "outputs": [],
   "source": [
    "#Librerias a implementar\n",
    "import os\n",
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Szo7P_3v00C"
   },
   "source": [
    "# Recolectar datos\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline1.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmqJPkjoA4oT"
   },
   "source": [
    "### Código de descarga del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HnVpNGuAvyFi"
   },
   "outputs": [],
   "source": [
    "if os.access('Telecust1.csv', os.F_OK) is False:\n",
    "    if platform.system() == 'Windows':\n",
    "        !curl https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/Telecust1.csv > Telecust1.csv\n",
    "    else:\n",
    "        !wget Telecust1.csv https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/Telecust1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbNSgxdfw0ix"
   },
   "source": [
    "### `Telecust1.csv.csv`:\n",
    "El dataset **`Telecust1.csv.csv`** contiene diferentes tipos de clientes que consumen un servicio de telecomunicación, los cuales deseamos clasificar en 4 categorias.<br> [Dataset source](https://www.kaggle.com/prathamtripathi/customersegmentation)\n",
    "\n",
    "- **region** --> region, ejemplo 2\n",
    "- **tenure** --> grado permanencia, ejemplo 40\n",
    "- **age** --> edad, ejemplo 52\n",
    "- **income** --> ingresos o sueldo, ejemplo 50 (un número que no representa una moneda real\n",
    "- **marital** --> si está casado o no\n",
    "- **address** --> dirección\n",
    "- **employ** --> empleo\n",
    "- **retire** --> si está retirado o no\n",
    "- **genero** --> 0 o 1 (no se sabe cual es cual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHHsGe1Qypde"
   },
   "source": [
    "# Procesar datos\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline2.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvzaKBMbyoiy"
   },
   "outputs": [],
   "source": [
    "# Una vez descargado el archivo en Colab.\n",
    "# Leerlo con Pandas y el método read_csv\n",
    "# Una vez extraida toda la información se almacena en df\n",
    "# A partir de df y el método describe(), mostrará la descripción estadistica básica del archivo que se guardará en des\n",
    "# Crear una fila nueva llamada Nan en el DataFrame  des,\n",
    "# que indica la cantidad de datos tipo Nan que tiene cada columna.\n",
    "# Para crear una nueva fila, se utilizará el operador loc, donde se indica el nombre\n",
    "# de la nueva fila y con que valores se completará.\n",
    "# La información será de los datos faltantes df.isna().sum()\n",
    "# Crear una fila nueva llamada %Nan en el DataFrame des,\n",
    "# Esta fila se completará con los porcentajes de Nan encontrados en cada columna.\n",
    "\n",
    "df = pd.read_csv(\"Telecust1.csv\")\n",
    "des = df.describe()\n",
    "des.loc['Nan'] = df.isna().sum()\n",
    "des.loc['%Nan'] = (df.isna().mean())*100\n",
    "des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cw9HbE88y3wu"
   },
   "outputs": [],
   "source": [
    "# Muestra las 5 primeras filas del DataFrame df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LirgXKpiy8dr"
   },
   "outputs": [],
   "source": [
    "# Cantidad de filas y columnas con shape\n",
    "# En la ubicación 0 corresponde a las filas\n",
    "print('Cantidad de datos en observacion:', df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BnzYdlRzBxz"
   },
   "source": [
    "# Explorar datos\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline3.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X2w_eW5QI-hf"
   },
   "outputs": [],
   "source": [
    "# Descripción estadistica básica del DataFrame df\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yH6oDykAzBMG"
   },
   "outputs": [],
   "source": [
    "# Se accede a la columna \"custcat\" para contar la frecuencia de los valores únicos (Cuenta la cantidad de clientes que tiene cada servicio).\n",
    "# como está repartida las categorias entre los clientes actuales\n",
    "df['custcat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5cQJRWdzTk3"
   },
   "outputs": [],
   "source": [
    "# Se representa graficamente la frecuencia de los servicios ofrecidos.\n",
    "# Esto permite explorar que tan balanceado está el dataset.\n",
    "# sns, alias de Seaborn\n",
    "# countplot(), gráfico de barras\n",
    "# Necesita toda la data\n",
    "# Se especifica la columna a representar, en este caso \"custcat\"\n",
    "sns.countplot(data=df, x=\"custcat\")\n",
    "\n",
    "# Muestra el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqVWUXPm0op-"
   },
   "source": [
    "Se puede ver que el dataset está bastante balanceado, no habrá una tendencia marcada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6f1b4PBcJAWU"
   },
   "outputs": [],
   "source": [
    "# Nos quedamos con aquellas columnas que podemos entender su relacion con el objetivo:'tenure', 'age', 'income', 'marital', 'retire', 'gender', 'custcat'\n",
    "# Para acceder a las columnas mencionadas se accede al DataFrame df[] y como \n",
    "# son varias columnas se indican los nombres en una lista\n",
    "# Almacenandose en el DataFrame df_clean\n",
    "df_clean = df[['tenure', 'age', 'income', 'marital', 'retire', 'gender', 'custcat']]\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdfLMthm0yyY"
   },
   "source": [
    "#### Normalización de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqEKDZw0KETM"
   },
   "source": [
    "Analizar cual es la distribución de los datos numéricos\n",
    "- tenure\n",
    "- age\n",
    "- income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJlDmX_F1ksA"
   },
   "outputs": [],
   "source": [
    "# Se representa graficamente la distribución de las edades de los clientes\n",
    "# Esto permite explorar que tan balanceado está el dataset.\n",
    "# sns, alias de Seaborn\n",
    "# displot(), gráfico de distribución\n",
    "# Necesita toda la data\n",
    "# Se especifica la columna a representar, en este caso \"age\"\n",
    "sns.displot(data=df_clean, x='age')\n",
    "# Muestra el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_X2CcMqdJ7z6"
   },
   "outputs": [],
   "source": [
    "# Permite explorar que tan balanceado está el dataset.\n",
    "# sns, alias de Seaborn\n",
    "# displot(), gráfico de distribución\n",
    "# Necesita toda la data\n",
    "# Se especifica la columna a representar, en este caso \"tenure\"\n",
    "sns.displot(data=df_clean, x='tenure')\n",
    "# Muestra el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xCksVi5J_V2"
   },
   "outputs": [],
   "source": [
    "# Permite explorar que tan balanceado está el dataset.\n",
    "# sns, alias de Seaborn\n",
    "# displot(), gráfico de distribución\n",
    "# Necesita toda la data\n",
    "# Se especifica la columna a representar, en este caso \"income\"\n",
    "sns.displot(data=df_clean, x='income')\n",
    "\n",
    "# Muestra el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d6BDobHKLHy"
   },
   "source": [
    "El \"ingreso\" sigue una distribución normal, pero con muchos outliers. Es por eso, que no utilizaremos el MinMaxScaler sino que se utilizará el StandardScaler a pesar de que \"tenure\" no siga una distribución normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zc6xNfbgKj4y"
   },
   "outputs": [],
   "source": [
    "# Normalización de datos\n",
    "# Se importa la herramienta de sklearn.preprocessing como StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Se crea una copia del DataFrame df_clean a df_norm\n",
    "df_norm = df_clean.copy()\n",
    "\n",
    "# Se crean los objetos; age_scaler, tenure_scaler y income_scaler a partir de la clase StandardScaler()\n",
    "age_scaler = StandardScaler()\n",
    "tenure_scaler = StandardScaler()\n",
    "income_scaler = StandardScaler()\n",
    "\n",
    "# Del DataFrame normalizado df_norm se emplea el método .loc para editar los datos de las columnas: age, tenure e income \n",
    "# Cada columna se completará con los datos normalizados\n",
    "# Para ello, se utiliza cada objeto creado y accede al método .fit_transform()\n",
    "# se indica la columna del DataFrame a normalizar \n",
    "# Al agregar .values, solo toma los valores, sin nombres de funciones (Los nombres de las columnas).\n",
    "df_norm.loc[:, 'age'] = age_scaler.fit_transform(df[['age']].values)\n",
    "df_norm.loc[:, 'tenure'] = tenure_scaler.fit_transform(df[['tenure']].values)\n",
    "df_norm.loc[:, 'income'] = income_scaler.fit_transform(df[['income']].values)\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7z_SuZlj3gbQ"
   },
   "source": [
    "# Entrenar modelo\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline4.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntY84fHj3q5q"
   },
   "source": [
    "El primer paso es obtener los datos que serán la entrada del sistema (X) y los datos que serán la salida del modelo estimador (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIg2_OQ43fqZ"
   },
   "outputs": [],
   "source": [
    "# Obtener los valores de X e y\n",
    "# En X se almacenarán todos los valores de las columnas excepto los valores de la columna \"custcat\"\n",
    "# axis=1 para que se elimine por filas\n",
    "# En y sólo se almacena los valores de la columna \"custcat\", que será la columna objetivo.\n",
    "# Para ello, se accede a la columna \"custcat\" del DataFrame df_norm usando corchetes.\n",
    "# En ambos caso, se implementa el método values para obtener solo los valores y que no vengan incluidos los nombres de las columnas.\n",
    "X = df_norm.drop('custcat', axis=1).values\n",
    "y = df_norm['custcat'].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbr-SnON4LuM"
   },
   "source": [
    "Siguiente paso es dividir el dataset en entrenamiento (train) y evaluación (test). Utilizaremos el criterio 70%30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BVD4YkjS4MW2"
   },
   "outputs": [],
   "source": [
    "# Se importa la herramienta de sklearn.model_selectionl como train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fijamos un \"random_state\" constante para que siempre el dataset se parta de la misma forma\n",
    "# para poder repetir los ensayos\n",
    "# Ojo! Los dataset de train y test son array numpy\n",
    "# Se importa la herramienta de la libreria  train_test_split()\n",
    "# Necesita los valores de X e y\n",
    "# test_size=0.3, permite indicar el porcentaje de valores para evaluar, equivalente a un 30%\n",
    "# random_state=42,  es un número fijo que utilizan comunmente en documentación, significa que para cada ejecución del algoritmo \n",
    "#se genere nuevos valores aleatorios\n",
    "# y los conjuntos de datos de entrenamiento y pruebas serán diferentes.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBh2fSnT4SED"
   },
   "source": [
    "### Crear un modelo de clasificación con vecinos cercanos (KNN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fi6Uv36UNiFz"
   },
   "source": [
    "#### Búsqueda del número de vecinos cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRw2jgPl4Xuc"
   },
   "outputs": [],
   "source": [
    "# Se importa la herramienta de sklearn.neighbors como KNeighborsClassifier\n",
    "# Se importa la métrica de sklearn.metrics como accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "K_MAX = 20\n",
    "# Crea un array de 20 elementos donde todos son ceros\n",
    "mean_acc = np.zeros((K_MAX))\n",
    "\n",
    "# Bucle itera 20 veces\n",
    "for i in range(K_MAX):\n",
    "    # Entrenar el modelo en cada iteración\n",
    "    # n_neighbors --> (k) número de vecinos cercanos\n",
    "    clf = KNeighborsClassifier(n_neighbors=(i+1)).fit(X_train,y_train)\n",
    "\n",
    "    # Prediccion\n",
    "    y_hat = clf.predict(X_test)   \n",
    "\n",
    "    # Evaluar el modelo\n",
    "    # Lo guarda en mean_acc\n",
    "    mean_acc[i] = accuracy_score(y_test, y_hat)\n",
    "\n",
    "#Representación gráfica de la exactitud de todas las iteraciones\n",
    "plt.plot(range(1, K_MAX+1), mean_acc,'darkBlue')\n",
    "# Nombra a los ejes\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('K')\n",
    "plt.tight_layout()\n",
    "# Muestra el gráfico\n",
    "plt.show()\n",
    "\n",
    "# Muestra el máximo accuracy que se almacenó en mean_acc\n",
    "# Del máximo accuracy busca su ubicación con mean_acc.argmax()+1\n",
    "print(f\"La mejor exactitud se obtuvo con {mean_acc.max():.2f} con K={mean_acc.argmax()+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NL0_TMz7Em4o"
   },
   "outputs": [],
   "source": [
    "# Una vez obtenido la ubicación de máximo accurary, se utiliza como números\n",
    "# de vecinos cercanos n_neighbors=13\n",
    "# Se entrana el modelo clasificador KNN con el método .fit()\n",
    "# Para luego utilizar .predict() a partir de clf\n",
    "clf = KNeighborsClassifier(n_neighbors=13).fit(X_train,y_train)\n",
    "y_hat = clf.predict(X_test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3IfjUuI4XnD"
   },
   "source": [
    "# Validar modelo\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline5.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMKONtv55zL8"
   },
   "outputs": [],
   "source": [
    "# Calcular la exactitud (accuracy)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_hat, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeLeYLYz6ZhO"
   },
   "outputs": [],
   "source": [
    "# Se utliza la matriz de confusión para evaluar la precisión de una clasificación.\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Necesita dos variables que contengan los valores a comparar\n",
    "cm = confusion_matrix(y_test, y_hat)\n",
    "\n",
    "# Código para realizar la representación gráfica con los resultados\n",
    "# Se crea la varible cmd, que almacena visualization de la Confusion Matrix \n",
    "# Necesita la variable cm que contiene los resultados de la comparación entre los valores reales y predicción\n",
    "# display_labels, se especifica las etiquetas de las categorias que se evalúan.\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=clf.classes_)\n",
    "\n",
    "\n",
    "# Con cmd.plot se especifica el mapa de colores reconocido por matplotlib.\n",
    "cmd.plot(cmap=plt.cm.Greens)\n",
    "\n",
    "# Para mostrar la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dZxGbjG96jR"
   },
   "source": [
    "# Utilizar modelo\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline6.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6euFUIFDRbmP"
   },
   "outputs": [],
   "source": [
    "# Supongamos que deseamos ver a que categoría pertenecemos\n",
    "# dado los siguientes datos\n",
    "age = 25\n",
    "tenure = 4\n",
    "income = df['income'].mean() # ganamos el promedio\n",
    "marital = 0 # no estamos casados\n",
    "retire = 0 # no estamos retirados\n",
    "gender = 1 # solo algun genero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e01cqkzTS8n3"
   },
   "outputs": [],
   "source": [
    "# El scaler espera como entrada una matriz (filas y columnas)\n",
    "# Por eso el doble corchete\n",
    "age_numpy = np.array([[age]])\n",
    "\n",
    "# Utilizamos float para convertir la matriz que retorna el scaler\n",
    "# a un número\n",
    "age_norm = float(age_scaler.transform(age_numpy))\n",
    "tenure_norm = float(tenure_scaler.transform(np.array([[tenure]])))\n",
    "income_norm = float(income_scaler.transform(np.array([[income]])))\n",
    "# El sistema espera como entrada \"X\" en este caso una sola fila pero varias\n",
    "# columnas, por eso el reshape(1, -1) donde el \"-1\" significa \"varias\"\n",
    "# (el sistema determina cuantas)\n",
    "X_prueba = np.array([tenure_norm, age_norm, income_norm, marital, retire, gender]).reshape(1, -1)\n",
    "print('Shape:', X_prueba.shape)\n",
    "print('Valores:\\n', X_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IYimWR0FTwK-"
   },
   "outputs": [],
   "source": [
    "# Se hace la predicción, a partir del objeto clasificador creado \"clf\"\n",
    "# Y con el método .predict()\n",
    "mi_categoria = clf.predict(X_prueba)\n",
    "mi_categoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7yzVZcZ9-4m"
   },
   "source": [
    "# Conclusión\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline7.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWAReOgo-B7b"
   },
   "source": [
    "En este ejemplo se obtuvo muy poca performance, pero se pudo ver como comparar muchos modelos KNN con distintos \"K\" y a su vez como ingresar un dato nuevo para predecir una categoría. Se podría probar con otros clasificadores pero el problema radica en la falta de datos"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
