{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67RBrvkUviuj"
   },
   "source": [
    "<a href=\"https://www.inove.com.ar\"><img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/PA%20Banner.png\" width=\"1000\" align=\"center\"></a>\n",
    "\n",
    "\n",
    "# Ejercicio de clasificación con Random Forest\n",
    "\n",
    "Ejemplo de clasificación utilizando random forest para la clasificación de drogadas que debería tomar un pasiente según su historial clínico<br>\n",
    "\n",
    "v2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7CzG7y83QyB"
   },
   "source": [
    "### Objetivos: \n",
    "*   Preprocesar los datos (descarga, lectura, limplieza y filtrado).\n",
    "*   Conocer como funciona el algoritmo clasificación con Random Forest.\n",
    "*   Evaluar el resultado el algoritmo clasificación con Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1NjxZxG--F0"
   },
   "source": [
    "**Random Forest:** Un bosque aleatorio es un metaestimador que ajusta una serie de clasificadores de árboles de decisión en varias submuestras del conjunto de datos y utiliza el promedio para mejorar la precisión predictiva y controlar el sobreajuste. \n",
    "\n",
    "Fuente: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2sSeyEovSw-"
   },
   "outputs": [],
   "source": [
    "#Librerias a implementar\n",
    "import os\n",
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Szo7P_3v00C"
   },
   "source": [
    "# Recolectar datos\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline1.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYJc7F_f3q1H"
   },
   "source": [
    "### Código de descarga del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HnVpNGuAvyFi"
   },
   "outputs": [],
   "source": [
    "if os.access('drug200.csv', os.F_OK) is False:\n",
    "    if platform.system() == 'Windows':\n",
    "        !curl https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/drug200.csv > drug200.csv\n",
    "    else:\n",
    "        !wget drug200.csv https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/drug200.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbNSgxdfw0ix"
   },
   "source": [
    "### `drug200.csv`:\n",
    "El dataset **`drug200.csv`** contiene diferentes tipos de drogas que se le dan a pacientes relativo a su historial clínico. El objetivo es dado un nuevo paciente clasificarlo y determinar que droga es la más apropiada para el.<br> [Dataset source](https://www.kaggle.com/jeevanrh/drug200csv)\n",
    "\n",
    "- **Age** --> edad, ejemplo 25\n",
    "- **Sex** --> género, ejemplo F(femenino), M(masculino)\n",
    "- **BP (Blood Pressure)** --> presión arterial, ejemplo HIGH(alta)\n",
    "- **Cholesterol** --> colesterol, ejemplo normal (NORMAL)\n",
    "- **Na / k** --> concentración de sodio/potasio en sangre, ejemplo 7.8\n",
    "- **Drug** --> droga suministrada, ejemplo drugC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHHsGe1Qypde"
   },
   "source": [
    "# Procesar datos\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline2.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvzaKBMbyoiy"
   },
   "outputs": [],
   "source": [
    "# Una vez descargado el archivo en Colab.\n",
    "# Leerlo con Pandas y el método read_csv\n",
    "# Una vez extraida toda la información se almacena en df\n",
    "# A partir de df y el método describe(), mostrará la descripción estadistica básica del archivo que se guardará en des\n",
    "# Crear una fila nueva llamada Nan en el DataFrame  des,\n",
    "# que indica la cantidad de datos tipo Nan que tiene cada columna.\n",
    "# Para crear una nueva fila, se utilizará el operador loc, donde se indica el nombre\n",
    "# de la nueva fila y con que valores se completará.\n",
    "# La información será de los datos faltantes df.isna().sum()\n",
    "# Crear una fila nueva llamada %Nan en el DataFrame des,\n",
    "# Esta fila se completará con los porcentajes de Nan encontrados en cada columna.\n",
    "\n",
    "df = pd.read_csv(\"drug200.csv\")\n",
    "des = df.describe()\n",
    "des.loc['Nan'] = df.isna().sum()\n",
    "des.loc['%Nan'] = (df.isna().mean())*100\n",
    "des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cw9HbE88y3wu"
   },
   "outputs": [],
   "source": [
    "# Muestra las 5 primeras filas del DataFrame df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LirgXKpiy8dr"
   },
   "outputs": [],
   "source": [
    "# Cantidad de filas y columnas con shape\n",
    "# En la ubicación 0 corresponde a las filas\n",
    "print('Cantidad de datos en observacion:', df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BnzYdlRzBxz"
   },
   "source": [
    "# Explorar datos\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline3.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yH6oDykAzBMG"
   },
   "outputs": [],
   "source": [
    "# Se accede a la columna \"Drug\" para contar la frecuencia de los valores únicos (Cuenta cuántas veces se dio cada droga).\n",
    "df['Drug'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5cQJRWdzTk3"
   },
   "outputs": [],
   "source": [
    "# Se representa graficamente la frecuencia de las drogas dadas.\n",
    "# Esto permite explorar que tan balanceado está el dataset.\n",
    "# Donde se puede ver en cuantos casos se suministró cada droga.\n",
    "# sns, alias de Seaborn\n",
    "# countplot(), gráfico de barras\n",
    "# Necesita toda la data\n",
    "# Se especifica la columna a representar, en este caso \"Drug\"\n",
    "sns.countplot(data=df, x=\"Drug\")\n",
    "\n",
    "# Muestra el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqVWUXPm0op-"
   },
   "source": [
    "Se puede observar que en la mayoría de los casos se suministra la drogaY o la drogaX, es muy probable que el modelo siga esta tendencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdfLMthm0yyY"
   },
   "source": [
    "#### Transformar variables categóricas texto, a clases numeradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJlDmX_F1ksA"
   },
   "outputs": [],
   "source": [
    "#Librerias a implementar\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Se hace una copia del df inicial en df_cod\n",
    "df_codificado = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lqa4Qq9dEGzr"
   },
   "outputs": [],
   "source": [
    "# Muestra las 5 primeras filas del DataFrame df_codificado\n",
    "df_codificado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31H2SQia_aWt"
   },
   "source": [
    " ### LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVk-JAUa_OiE"
   },
   "outputs": [],
   "source": [
    "# Se crea el objeto \"le\" que significa label encoder a partir de la clase LabelEncoder()\n",
    "# Del objeto \"le\" se puede acceder al método fit_transform con la notación del punto, para que \n",
    "# asigne un número a cada categoría existente en la columna.\n",
    "le_sex = LabelEncoder()\n",
    "label_encoding = le_sex.fit_transform(df_codificado['Sex'])\n",
    "label_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HN1AaOnYAmnQ"
   },
   "source": [
    "### OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXi11tKiAgxE"
   },
   "outputs": [],
   "source": [
    "# Se crea el objeto \"onehot_encoder\" a partir de la clase OneHotEncoder()\n",
    "# Se indica sparse=False para que la matriz no esté dispersa.\n",
    "# A partir del objeto creado \"onehot_encoder\", se accede al método fit_transform()\n",
    "# Importante; para aplicar el One Hot Encoder se necesita que los datos esten en un array \n",
    "# Con el label enconde aplicado, haciendo el ajuste con reshape(-1, 1)\n",
    "ohe_sex = OneHotEncoder(sparse=False)\n",
    "one_hot_encoding = ohe_sex.fit_transform(label_encoding.reshape(-1, 1))\n",
    "one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RlVfFFMpBqjr"
   },
   "outputs": [],
   "source": [
    "# Crear un DataFrame con los resultados del \"one_hot_encoding\"\n",
    "# Necesita indicar los datos (en su formato array), las columnas a través de \"le\"(label encoder)\n",
    "# Con dtype=int se indica el tipo de dato como entero.\n",
    "df_ohe = pd.DataFrame(one_hot_encoding, columns=le_sex.classes_, dtype=int)\n",
    "df_ohe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MC9o62yhC6kM"
   },
   "outputs": [],
   "source": [
    "# Agregar sufijo a cada columna del DataFrame \"df_ohe\"\n",
    "# df_ohe, el DataFrame  se sobreescribe con los nuevos nombres de las columnas, \n",
    "# quedando Sex_F, Sex_M\n",
    "# Para ello, a partir del df_ohe se accede al método add_prefix()\n",
    "# Donde se indica el nombre de texto que se le quiere agregar a la columna \n",
    "# + concatenando con _ para separar ambos nombres\n",
    "df_ohe = df_ohe.add_prefix('Sex'+'_')\n",
    "df_ohe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BxTmXczlFDhN"
   },
   "outputs": [],
   "source": [
    "# Unir las nuevas columnas del DataFrame \"df_ohe\" con el DataFrame inicial\n",
    "# Para ello, se empleará el método join() en \n",
    "# Indicandole \n",
    "df_codificado = df_codificado.join(df_ohe)\n",
    "df_codificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ex9Zxgq02sW0"
   },
   "outputs": [],
   "source": [
    "# Eliminar la columna \"Sex\" con datos strings del DataFrame\n",
    "df_codificado = df_codificado.drop([\"Sex\"], axis=1)\n",
    "df_codificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-Y-eHwV08v3"
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(df, column):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    label_encoding = le.fit_transform(df_copy[column])\n",
    "\n",
    "    # OneHotEncoder\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    one_hot_encoding = onehot_encoder.fit_transform(label_encoding.reshape(-1, 1))\n",
    "\n",
    "    # Crear las columnas con el resultado del encoder\n",
    "    one_hot_encoding_df = pd.DataFrame(one_hot_encoding, columns=le.classes_, dtype=int)\n",
    "\n",
    "    # Agregar sufijo\n",
    "    one_hot_encoding_df = one_hot_encoding_df.add_prefix(column+'_')\n",
    "\n",
    "    # Unir nuevas columnas al dataset\n",
    "    df_copy = df_copy.join(one_hot_encoding_df)\n",
    "\n",
    "    # Eliminar vieja columna del dataset\n",
    "    df_copy = df_copy.drop([column], axis=1)\n",
    "    return df_copy, le, onehot_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mXf8mxK2qps"
   },
   "outputs": [],
   "source": [
    "df_codificado, le_bp, ohe_bp = one_hot_encoding(df_codificado, 'BP')\n",
    "df_codificado, le_cholesterol, ohe_cholesterol = one_hot_encoding(df_codificado, 'Cholesterol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcMF3cQq3NHC"
   },
   "outputs": [],
   "source": [
    "# Muestra las 5 primeras filas del DataFrame df_codificado\n",
    "df_codificado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7z_SuZlj3gbQ"
   },
   "source": [
    "# Entrenar modelo\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline4.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntY84fHj3q5q"
   },
   "source": [
    "El primer paso es obtener los datos que serán la entrada del sistema (X) y los datos que serán la salida del modelo estimador (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIg2_OQ43fqZ"
   },
   "outputs": [],
   "source": [
    "# Obtener los valores de X e y\n",
    "# En X se almacenarán todos los valores de las columnas excepto los valores de la columna \"Drugs\"\n",
    "# En y sólo se almacena los valores de la columna \"Drugs\", que será la columna objetivo.\n",
    "# Para ello, se accede a la columna \"Drugs\" del DataFrame df_cod usando corchetes.\n",
    "# En ambos caso, se implementa el método values para obtener solo los valores y que no vengan incluidos los nombres de las columnas.\n",
    "\n",
    "X = df_codificado.drop('Drug', axis=1).values\n",
    "y = df_codificado['Drug'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbr-SnON4LuM"
   },
   "source": [
    "Siguiente paso es dividir el dataset en entrenamiento (train) y evaluación (test). Utilizaremos el criterio 70%30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BVD4YkjS4MW2"
   },
   "outputs": [],
   "source": [
    "# Se importa la herramienta de sklearn.model_selectionl como train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fijamos un \"random_state\" constante para que siempre el dataset se parta de la misma forma\n",
    "# para poder repetir los ensayos\n",
    "# Ojo! Los dataset de train y test son array numpy\n",
    "# Se importa la herramienta de la libreria  train_test_split()\n",
    "# Necesita los valores de X e y\n",
    "# test_size=0.3, permite indicar el porcentaje de valores para evaluar, equivalente a un 30%\n",
    "# random_state=42,  es un número fijo que utilizan comunmente en documentación, significa que para cada ejecución del algoritmo \n",
    "#se genere nuevos valores aleatorios\n",
    "# y los conjuntos de datos de entrenamiento y pruebas serán diferentes.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBh2fSnT4SED"
   },
   "source": [
    "#### Crear un modelo de clasificación con random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRw2jgPl4Xuc"
   },
   "outputs": [],
   "source": [
    "# Se importa la herramienta de sklearn.ensemble como RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Se crea el objeto clf a partir de la clase RandomForestClassifier()\n",
    "# La cual necesita especificar los siguientes parámetros:\n",
    "# n_estimators --> Cantidad de árboles (por defecto 100)\n",
    "# max_depth --> Máxima profundiad del árbol, por defecto sin límite\n",
    "# criterion --> La entropía es una medida de información que indica el desorden de las características con el objetivo\n",
    "# Criterio para crear los nodos (entropy o gini)\n",
    "# random_state=0, controla tanto la aleatoriedad de las muestras utilizadas al construir árboles\n",
    "# Las semillas aleatorias enteras populares son 0 y 42.\n",
    "# Del objeto se accede al método fit, para el entrenamiento y predict para la predicción.\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=4, max_depth=5, criterion='entropy', random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_hat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3IfjUuI4XnD"
   },
   "source": [
    "# Validar modelo\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline5.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMKONtv55zL8"
   },
   "outputs": [],
   "source": [
    "# Calcular la exactitud (accuracy)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_hat, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeLeYLYz6ZhO"
   },
   "outputs": [],
   "source": [
    "# Se utliza la matriz de confusión para evaluar la precisión de una clasificación.\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Necesita dos variables que contengan los valores a comparar\n",
    "cm = confusion_matrix(y_test, y_hat)\n",
    "\n",
    "# Código para realizar la representación gráfica con los resultados\n",
    "# Se crea la varible cmd, que almacena visualization de la Confusion Matrix \n",
    "# Necesita la variable cm que contiene los resultados de la comparación entre los valores reales y predicción\n",
    "# display_labels, se especifica las etiquetas de las categorias que se evalúan.\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=clf.classes_)\n",
    "\n",
    "# Con cmd.plot se especifica el mapa de colores reconocido por matplotlib.\n",
    "cmd.plot(cmap=plt.cm.Reds)\n",
    "\n",
    "# Para mostrar la figura\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dZxGbjG96jR"
   },
   "source": [
    "# Utilizar modelo\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline6.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gh9BT5uDWVoU"
   },
   "outputs": [],
   "source": [
    "df_prueba = pd.DataFrame({\"Age\":[28],\"Na_to_K\": [29.400], \"Sex\": [\"F\"], \"BP\": [\"HIGH\"], \"Cholesterol\": [\"HIGH\"]})\n",
    "df_prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vLJSPEZLNmHk"
   },
   "outputs": [],
   "source": [
    "# Implementar el label encoder\n",
    "le_transform_sex = le_sex.transform(df_prueba['Sex'])\n",
    "le_transform_bp = le_bp.transform(df_prueba['BP'])\n",
    "le_transform_cholesterol  = le_cholesterol.transform(df_prueba['Cholesterol'])\n",
    "\n",
    "# Implementar el OneHotEncoder\n",
    "ohe_transform_sex = ohe_sex.transform(le_transform_sex.reshape(-1, 1))\n",
    "ohe_transform_bp = ohe_bp.transform(le_transform_bp.reshape(-1, 1))\n",
    "ohe_transform_cholesterol  = ohe_cholesterol.transform(le_transform_cholesterol.reshape(-1, 1))\n",
    "\n",
    "# Armar un DataFrame para cada OneHotEncoder\n",
    "df_ohe_sex = pd.DataFrame(ohe_transform_sex, columns=le_sex.classes_, dtype=int).add_prefix('Sex'+'_')\n",
    "df_ohe_bp = pd.DataFrame(ohe_transform_bp, columns=le_bp .classes_, dtype=int).add_prefix('BP'+'_')\n",
    "df_ohe_cholesterol = pd.DataFrame(ohe_transform_cholesterol, columns=le_cholesterol.classes_, dtype=int).add_prefix('Cholesterol'+'_')\n",
    "\n",
    "# Unir\n",
    "df_unido = df_ohe_sex.join(df_ohe_bp)\n",
    "df_unido = df_unido.join(df_ohe_cholesterol)\n",
    "df_unido = df_prueba.join(df_unido)\n",
    "\n",
    "# # Eliminar vieja columna del dataset\n",
    "df_unido = df_unido.drop(['Sex'], axis=1)\n",
    "df_unido = df_unido.drop(['BP'], axis=1)\n",
    "df_unido = df_unido.drop(['Cholesterol'], axis=1)\n",
    "df_unido \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TkijtPgUfxjN"
   },
   "outputs": [],
   "source": [
    "X_prueba = df_unido.values\n",
    "y_hat_prueba = clf.predict(X_prueba)\n",
    "y_hat_prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nOS9pGhBEhSL"
   },
   "outputs": [],
   "source": [
    "# Se importa tree de sklearn\n",
    "from sklearn import tree\n",
    "\n",
    "# Tomo el primer árbol de decisión del bosque para dibujar\n",
    "estimator = clf.estimators_[0]  \n",
    "\n",
    "# Obtengo los nombres de las columnas utilizadas y las clases posibles\n",
    "feature_names = df_codificado.drop('Drug', axis=1).columns\n",
    "class_names = df_codificado['Drug'].unique().tolist()\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPZ74KDO95wR"
   },
   "outputs": [],
   "source": [
    "# Se importa tree de sklearn\n",
    "from sklearn import tree\n",
    "\n",
    "# Tomo el primer árbol de decisión del bosque para dibujar\n",
    "estimator = clf.estimators_[0]  ## estimator--> DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features='auto',random_state=209652396)\n",
    "\n",
    "# Obtengo los nombres de las columnas utilizadas y las clases posibles\n",
    "# del DataFrame \"df_codificado\" elimina la columna \"Drug\" y obtiene los nombres de las columnas\n",
    "#features_names devuelve los nombre de las columnas--> Index(['Age', 'Na_to_K', 'Sex_F', 'Sex_M', 'BP_HIGH', 'BP_LOW', \n",
    "#'BP_NORMAL','Cholesterol_HIGH', 'Cholesterol_NORMAL'], dtype='object')\n",
    "feature_names = df_codificado.drop('Drug', axis=1).columns\n",
    "\n",
    "# Accede al DataFrame \"df_codificado\" a su columna \"Drug\"\n",
    "# Con el método .unique() busca las categorías únicas \n",
    "# y devuelve la información en una lista con el método .tolist()\n",
    "# class_names las categorías que representan la columna---> ['drugY', 'drugC', 'drugX', 'drugA', 'drugB']\n",
    "class_names = df_codificado['Drug'].unique().tolist()\n",
    "\n",
    "# Se crea el espacio para dibujar con fig = plt.figure(figsize=(16, 9))\n",
    "# Se crea el espacio para el gráfico ax = fig.add_subplot()\n",
    "fig = plt.figure(figsize=(60,40))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "# tree, variable del árbol, accede al método plot_tree para representarlo graficamente\n",
    "# Indicando los parámetros:\n",
    "# estimator --> Cantidad de árboles, el primero indicado en estimator = clf.estimators_[0]\n",
    "# feature_names = feature_names, los nombre de las columnas--> Index(['Age', 'Na_to_K', 'Sex_F', 'Sex_M', 'BP_HIGH', 'BP_LOW', \n",
    "#'BP_NORMAL','Cholesterol_HIGH', 'Cholesterol_NORMAL'], dtype='object')\n",
    "# class_names=class_names, class_names las categorías que representan la columna---> ['drugY', 'drugC', 'drugX', 'drugA', 'drugB']\n",
    "# filles=True, Cuando se establece en True, pinta los nodos para indicar la clase mayoritaria para la clasificación.\n",
    "# ax=ax, Ejes para trazar el gráfico.\n",
    "# Fuente: https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html\n",
    "tree.plot_tree(estimator,\n",
    "               feature_names = feature_names, \n",
    "               class_names=class_names,\n",
    "               filled = True,\n",
    "               ax=ax);\n",
    "# Muetra la figura\n",
    "plt.show()\n",
    "# Nombre de la imagen\n",
    "filename = 'drugtree.png'\n",
    "# fig.savefig, guarda la imagen con el nombre asignado.\n",
    "fig.savefig(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7yzVZcZ9-4m"
   },
   "source": [
    "# Conclusión\n",
    "<img src=\"https://raw.githubusercontent.com/InoveAlumnos/dataset_analytics_python/master/images/Pipeline7.png\" width=\"1000\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWAReOgo-B7b"
   },
   "source": [
    "En este ejemplo no fue muy dificil conseguir un buen resultado ya que no era un dataset complejo. La misma estrategía de trabajo puede aplicarse para otros datasets"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
